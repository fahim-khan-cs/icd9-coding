{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "00. Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud-bigquery in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (3.18.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery) (2.7.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery) (2.17.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery) (24.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery) (2.4.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.25.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.28.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (5.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.3.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (0.34.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud-vision in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (3.7.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-vision) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-vision) (1.23.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-vision) (2.17.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-cloud-vision) (2.28.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.62.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.62.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.62.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (5.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (4.66.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (2.16.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.0.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.7)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: rich in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (7.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (3.8.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (4.3.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (2.2.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from sklearn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (1.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/fahimkhan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (3.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Notebook environment setup\n",
    "%pip install google-cloud-bigquery\n",
    "%pip install google-cloud\n",
    "%pip install google-cloud-vision\n",
    "%pip install tqdm\n",
    "%pip install numpy\n",
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "%pip install gensim\n",
    "%pip install pandas\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import torch\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from model_utils import train_model, score_model, evaluate\n",
    "from model_utils import ArrayDataset, D2VDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 01. Fetch Discharge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch MIMIC-III Discharge Summaries from BigQuery\n",
    "credentials = service_account.Credentials.from_service_account_file('/users/fahimkhan/Downloads/endless-upgrade-415215-8ffb43b4399b.json')\n",
    "\n",
    "project_id = 'endless-upgrade-415215'\n",
    "client = bigquery.Client(credentials= credentials,project=project_id)\n",
    "\n",
    "# Query all discharge summaries from the note events table\n",
    "train_query = client.query(\"\"\"\n",
    "  SELECT t1.HADM_ID, STRING_AGG(CAST(t1.TEXT AS STRING), ' ') AS concatenated_text\n",
    "  FROM `endless-upgrade-415215.mimic3_notes.noteevents` AS t1\n",
    "  JOIN (\n",
    "      SELECT DISTINCT HADM_ID\n",
    "      FROM `endless-upgrade-415215.mimic3_notes.noteevents`\n",
    "  ) AS t2\n",
    "  ON t1.HADM_ID = t2.HADM_ID\n",
    "  WHERE t1.CATEGORY = \"Discharge summary\"\n",
    "  GROUP BY t1.HADM_ID\n",
    " \"\"\")\n",
    "\n",
    "# Run query\n",
    "train_ds = train_query.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52726\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Load labels\n",
    "labels = np.load('data/finallabels.npz')['arr_0']\n",
    "total_patients = labels.shape[0]\n",
    "labels_tensor = torch.FloatTensor(labels)\n",
    "\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 02. Doc2Vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize Discharge Summaries ~5mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(results, tokens_only=False):\n",
    "    i = 0\n",
    "    for row in results:\n",
    "        tokens = gensim.utils.simple_preprocess(row[1])\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "        i+=1\n",
    "\n",
    "train_corpus = list(read_corpus(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Doc2Vec Model\n",
    "\n",
    "Avg Time ~ 2.5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_vector_size = 128\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec(vector_size=d2v_vector_size, \n",
    "                                          min_count=2, \n",
    "                                          epochs=5,\n",
    "                                          dbow_words=1)\n",
    "d2v_model.build_vocab(train_corpus)\n",
    "d2v_model.train(train_corpus, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = np.array([d2v_model.dv[i] for i in range(len(d2v_model.dv))])\n",
    "\n",
    "# Calculate the number of samples for each set\n",
    "percentage = 0.1\n",
    "num_samples = int(np.floor(percentage * len(doc_vectors)))\n",
    "train_samples = int(np.floor(0.7 * num_samples))\n",
    "valid_samples = int(np.floor(0.15 * num_samples))  # Assuming 50% of the leftovers for validation\n",
    "test_samples = num_samples - train_samples - valid_samples\n",
    "\n",
    "# Slice the arrays to create train/test sets\n",
    "train_data = doc_vectors[:train_samples]\n",
    "train_labels = labels[:train_samples]\n",
    "\n",
    "valid_data = doc_vectors[train_samples:train_samples + valid_samples]\n",
    "valid_labels = labels[train_samples:train_samples + valid_samples]\n",
    "\n",
    "test_data = doc_vectors[train_samples + valid_samples:train_samples + valid_samples + test_samples]\n",
    "test_labels = labels[train_samples + valid_samples:train_samples + valid_samples + test_samples]\n",
    "\n",
    "# Create ArrayDataset objects for train, validation, and test sets\n",
    "train_dataset = D2VDataset(train_data, train_labels)\n",
    "valid_dataset = D2VDataset(valid_data, valid_labels)\n",
    "test_dataset = D2VDataset(test_data, test_labels)\n",
    "\n",
    "# Create DataLoader objects for train, validation, and test sets\n",
    "batch_size = 32  # Choose your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Neural Network to extract D2V features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.9):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=1 - dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training FCNN using D2V output\n",
    "\n",
    "Avg Time ~ 0.5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6932\n",
      "Epoch [2/5], Loss: 0.6932\n",
      "Epoch [3/5], Loss: 0.6931\n",
      "Epoch [4/5], Loss: 0.6931\n",
      "Epoch [5/5], Loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "# Define input size and output size\n",
    "input_size = 128\n",
    "hidden_size = 64\n",
    "output_size = 6918\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Create an instance of the model\n",
    "fcnn_model = FCNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(fcnn_model.parameters(), lr=0.001)\n",
    "\n",
    "d2v_outputs = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    #for i in range(len(d2v_model.dv)):\n",
    "    for i in range(5722):\n",
    "        input_data = torch.tensor(d2v_model.dv[i], dtype=torch.float)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = fcnn_model(input_data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, labels_tensor[i])\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print loss every epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.16248567018593693, Valid F1: 0.06870397123992839\n",
      "Epoch 2, Loss: 0.018996160686144542, Valid F1: 0.0537811714610336\n",
      "Epoch 3, Loss: 0.018570418477636474, Valid F1: 0.09648207950916379\n",
      "Epoch 4, Loss: 0.018369201875837713, Valid F1: 0.08705806341553426\n",
      "Epoch 5, Loss: 0.018319569327386803, Valid F1: 0.08166270409791393\n",
      "Epoch 6, Loss: 0.018250893592706013, Valid F1: 0.06897344098675019\n",
      "Epoch 7, Loss: 0.01819218653414784, Valid F1: 0.06703061056673174\n",
      "Epoch 8, Loss: 0.018091250387630587, Valid F1: 0.07779081127628033\n",
      "Epoch 9, Loss: 0.01810520860077492, Valid F1: 0.06930783023847704\n",
      "Epoch 10, Loss: 0.018123624878453797, Valid F1: 0.08346485868002165\n",
      "Epoch 11, Loss: 0.01804174426621918, Valid F1: 0.07310014459843396\n",
      "Epoch 12, Loss: 0.01799318265844265, Valid F1: 0.0736259347800419\n",
      "Epoch 13, Loss: 0.01796421450402202, Valid F1: 0.08484381416438888\n",
      "Epoch 14, Loss: 0.01794897755286817, Valid F1: 0.06548282429244313\n",
      "Epoch 15, Loss: 0.01792500033203898, Valid F1: 0.08280347827798831\n",
      "Epoch 16, Loss: 0.01785752279202229, Valid F1: 0.06820751734551686\n",
      "Epoch 17, Loss: 0.01788505930292966, Valid F1: 0.06865524151914859\n",
      "Epoch 18, Loss: 0.01782110121486516, Valid F1: 0.058516599859588785\n",
      "Epoch 19, Loss: 0.017853328227547222, Valid F1: 0.06787158861681246\n",
      "Epoch 20, Loss: 0.01781214014948185, Valid F1: 0.06851701266782302\n",
      "Epoch 21, Loss: 0.017744772393127967, Valid F1: 0.06279835371438128\n",
      "Epoch 22, Loss: 0.017716857468195516, Valid F1: 0.07447640184595777\n",
      "Epoch 23, Loss: 0.017651752432294446, Valid F1: 0.08457418505886345\n",
      "Epoch 24, Loss: 0.017635294693875415, Valid F1: 0.06721776190749454\n",
      "Epoch 25, Loss: 0.017583972991219367, Valid F1: 0.07596407526884803\n",
      "Epoch 26, Loss: 0.017559997753464972, Valid F1: 0.06904852398151208\n",
      "Epoch 27, Loss: 0.017584584958465963, Valid F1: 0.06267570525119809\n",
      "Epoch 28, Loss: 0.017514789380646986, Valid F1: 0.07518065263504356\n",
      "Epoch 29, Loss: 0.017460681184933616, Valid F1: 0.0626229405597391\n",
      "Epoch 30, Loss: 0.017402561261029594, Valid F1: 0.06802969856015935\n",
      "Epoch 31, Loss: 0.017367753906753557, Valid F1: 0.06985653446179681\n",
      "Epoch 32, Loss: 0.017370827463937217, Valid F1: 0.06466527120757473\n",
      "Epoch 33, Loss: 0.017341462052266658, Valid F1: 0.06377915714194178\n",
      "Epoch 34, Loss: 0.017212928441385257, Valid F1: 0.07170252158146945\n",
      "Epoch 35, Loss: 0.01719141191931377, Valid F1: 0.08330093725990763\n",
      "Epoch 36, Loss: 0.0171689052006294, Valid F1: 0.08885526585578335\n",
      "Epoch 37, Loss: 0.0171321677044034, Valid F1: 0.0683449959031943\n",
      "Epoch 38, Loss: 0.017044546114730424, Valid F1: 0.07997063383328797\n",
      "Epoch 39, Loss: 0.017014855663452684, Valid F1: 0.08146804825475577\n",
      "Epoch 40, Loss: 0.016916279672998292, Valid F1: 0.06585812558764612\n",
      "Epoch 41, Loss: 0.016925546332615716, Valid F1: 0.07407957348848028\n",
      "Epoch 42, Loss: 0.016891274432619584, Valid F1: 0.07720769427769449\n",
      "Epoch 43, Loss: 0.01683097746993961, Valid F1: 0.07458512102875922\n",
      "Epoch 44, Loss: 0.01677104125827037, Valid F1: 0.07012630120963391\n",
      "Epoch 45, Loss: 0.01673418454472618, Valid F1: 0.07094437817709885\n",
      "Epoch 46, Loss: 0.016645730103783566, Valid F1: 0.071521953401584\n",
      "Epoch 47, Loss: 0.016576847198001784, Valid F1: 0.06422334045878982\n",
      "Epoch 48, Loss: 0.016542772585847253, Valid F1: 0.07445889337577123\n",
      "Epoch 49, Loss: 0.016413349505706595, Valid F1: 0.07150723252127554\n",
      "Epoch 50, Loss: 0.016389126054428774, Valid F1: 0.07799125359104458\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "# 10% data, 5 Epochs ~ 8.5 mins\n",
    "\n",
    "# Define input size and output size\n",
    "input_size = 128\n",
    "hidden_size = 64\n",
    "output_size = 6918\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "# Create an instance of the model\n",
    "fcnn_model = FCNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(fcnn_model.parameters(), lr=0.001)\n",
    "\n",
    "tlosses, tprecs, trecs, tf1s = [],[],[], []\n",
    "vlosses, vprecs, vrecs, vf1s = [],[],[], []\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  tloss, tprec, trec, tf1 = train_model(fcnn_model, train_loader, criterion, optimizer)\n",
    "  vloss, vprec, vrec, vf1 = evaluate(fcnn_model, test_loader, criterion)\n",
    "\n",
    "  tlosses.append(tloss)\n",
    "  tprecs.append(tprec)\n",
    "  trecs.append(trec)\n",
    "  tf1s.append(tf1)\n",
    "\n",
    "  vlosses.append(vloss)\n",
    "  vrecs.append(vprec)\n",
    "  vrecs.append(vrec)\n",
    "  vf1s.append(vf1)\n",
    "\n",
    "  is_best = vf1 > best_val_f1\n",
    "  best_val_f1 = best_val_f1*(not is_best) + vf1*is_best\n",
    "\n",
    "  # if is_best:\n",
    "  #   best_val_f1 = vf1\n",
    "    # torch.save(model, \"myCNN.pth\", _use_new_zipfile_serialization=False)\n",
    "\n",
    "  print(f'Epoch {epoch+1}, Loss: {tlosses[-1]}, Valid F1: {vf1s[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn_model.eval()  # Setting the model to evaluation mode\n",
    "\n",
    "all_true_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = fcnn_model(inputs)\n",
    "        # print(inputs.shape, labels.shape, outputs.shape)\n",
    "        all_outputs.extend(outputs.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.005 precision: 0.25390851187028796 recall: 0.05282814288295855 f1: 0.08745948641236513\n",
      "threshold: 0.05 precision: 0.2570220477197144 recall: 0.05124036608863168 f1: 0.08544605652894136\n",
      "threshold: 0.1 precision: 0.25826972010177296 recall: 0.048856799037304166 f1: 0.08216960129528354\n",
      "threshold: 0.2 precision: 0.26446860750612894 recall: 0.04529888855512139 f1: 0.07734919983586298\n",
      "threshold: 0.3 precision: 0.26939405634888963 recall: 0.041881675267010435 f1: 0.0724931193851579\n",
      "threshold: 0.4 precision: 0.27595044852625905 recall: 0.038712770420087264 f1: 0.06789993693504238\n",
      "threshold: 0.5 precision: 0.2791353383458515 recall: 0.03554119547657491 f1: 0.06305397802664335\n"
     ]
    }
   ],
   "source": [
    "thresh_ls = [0.005, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "for i in thresh_ls:\n",
    "  print('threshold:', i,\n",
    "        *[\"{}: {}\".format(name, num) for name, num in zip(\n",
    "          [\"precision\", \"recall\",\"f1\"],\n",
    "          score_model(all_true_labels, all_outputs, thresh=i))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 03. **CNN Part**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Weights\n",
    "data = np.load('data/w2v_stack3.npz')\n",
    "\n",
    "#Change to (Batch, Feats/Channels, Sequences)\n",
    "data = torch.FloatTensor(data['arr_0']).permute(2,1,0)\n",
    "weights = np.load('data/loss_weights.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "labels = np.load('data/finallabels.npz')['arr_0']\n",
    "total_patients = labels.shape[0]\n",
    "labels = torch.FloatTensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_FEATURE_SIZE = 100\n",
    "NUM_LABELS = labels.shape[1]\n",
    "MAX_LENGTH = 700\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix=None):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "\n",
    "        if self.embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "\n",
    "        input_length = 100\n",
    "\n",
    "        # Define convolutional layers for 3 different kernel sizes\n",
    "        k1, k2, k3 = 3,4,5\n",
    "        self.conv1 = nn.Conv1d(in_channels=VECTOR_FEATURE_SIZE, out_channels=64, kernel_size=k1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=VECTOR_FEATURE_SIZE, out_channels=64, kernel_size=k2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=VECTOR_FEATURE_SIZE, out_channels=64, kernel_size=k3)\n",
    "\n",
    "        # Max Pooling\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(output_size=1)\n",
    "\n",
    "        # Define a dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(64 * 3, NUM_LABELS)\n",
    "\n",
    "        self.activationR = nn.ReLU()\n",
    "        self.activationS = nn.Sigmoid() #Actually not using this because the loss function handles it\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.embedding_matrix is not None:\n",
    "            # Convert token IDs to embeddings\n",
    "            x = self.embedding(x)\n",
    "\n",
    "        x = x.float()\n",
    "\n",
    "        # Apply convolution\n",
    "        x1 = F.pad(x,(1,1))\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.activationR(x1)\n",
    "        x2 = F.pad(x,(1,2))\n",
    "        x2 = self.conv2(x)\n",
    "        x2 = self.activationR(x2)\n",
    "        x3 = F.pad(x,(2,2))\n",
    "        x3 = self.conv3(x)\n",
    "        x3 = self.activationR(x3)\n",
    "\n",
    "        # Apply global max pooling to each convolutional layer's output\n",
    "        x1 = self.global_max_pool(x1).squeeze(2)\n",
    "        x2 = self.global_max_pool(x2).squeeze(2)\n",
    "        x3 = self.global_max_pool(x3).squeeze(2)\n",
    "\n",
    "        # Concatenate the pooled features from the three convolutional layers\n",
    "        x = torch.cat((x1, x2, x3), 1)\n",
    "\n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.10\n",
    "num_samples = int(np.floor(percentage * total_patients))\n",
    "train_samples = int(np.floor(0.7 * num_samples))\n",
    "leftovers = num_samples - train_samples\n",
    "valid_samples = train_samples + int(np.floor(0.5*leftovers))\n",
    "start_test_samples = num_samples - valid_samples\n",
    "\n",
    "# Initialize Dataset\n",
    "train_dataset = ArrayDataset(data[:train_samples, :, :],\n",
    "                              labels[:train_samples])\n",
    "valid_dataset = ArrayDataset(data[train_samples:valid_samples, :, :],\n",
    "                            labels[train_samples:valid_samples])\n",
    "test_dataset = ArrayDataset(data[start_test_samples:num_samples, :, :],\n",
    "                              labels[start_test_samples:num_samples])\n",
    "\n",
    "# Initialize DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train CNN part model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.185114973300212, Valid F1: 0.00600193880847875\n",
      "Epoch 2, Loss: 5.157990416964969, Valid F1: 0.0071628597926002464\n",
      "Epoch 3, Loss: 4.738494074022448, Valid F1: 0.008219478206535699\n",
      "Epoch 4, Loss: 4.80270152800792, Valid F1: 0.009942361780542544\n",
      "Epoch 5, Loss: 4.536849837045412, Valid F1: 0.011084900467470491\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "# 10% data, 5 Epochs ~ 8.5 mins\n",
    "\n",
    "model = MyModel()\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "tlosses, tprecs, trecs, tf1s = [],[],[], []\n",
    "vlosses, vprecs, vrecs, vf1s = [],[],[], []\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  tloss, tprec, trec, tf1 = train_model(model, train_loader, criterion, optimizer)\n",
    "  vloss, vprec, vrec, vf1 = evaluate(model, test_loader, criterion)\n",
    "\n",
    "  tlosses.append(tloss)\n",
    "  tprecs.append(tprec)\n",
    "  trecs.append(trec)\n",
    "  tf1s.append(tf1)\n",
    "\n",
    "  vlosses.append(vloss)\n",
    "  vrecs.append(vprec)\n",
    "  vrecs.append(vrec)\n",
    "  vf1s.append(vf1)\n",
    "\n",
    "  is_best = vf1 > best_val_f1\n",
    "  best_val_f1 = best_val_f1*(not is_best) + vf1*is_best\n",
    "\n",
    "  # if is_best:\n",
    "  #   best_val_f1 = vf1\n",
    "    # torch.save(model, \"myCNN.pth\", _use_new_zipfile_serialization=False)\n",
    "\n",
    "  print(f'Epoch {epoch+1}, Loss: {tlosses[-1]}, Valid F1: {vf1s[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Setting the model to evaluation mode\n",
    "\n",
    "all_true_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        # print(inputs.shape, labels.shape, outputs.shape)\n",
    "        all_outputs.extend(outputs.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.005 precision: 0.005430653218971768 recall: 0.5024583296586995 f1: 0.0107451708438315\n",
      "threshold: 0.05 precision: 0.005458236111413131 recall: 0.4948183390050765 f1: 0.010797368739154269\n",
      "threshold: 0.1 precision: 0.005465280431274714 recall: 0.4804477251257711 f1: 0.01080761996633599\n",
      "threshold: 0.2 precision: 0.005607303775326335 recall: 0.4667975390149474 f1: 0.011081493523103433\n",
      "threshold: 0.3 precision: 0.005658425100023264 recall: 0.44343219181823096 f1: 0.011174260827628617\n",
      "threshold: 0.4 precision: 0.005589148302828285 recall: 0.411702671261918 f1: 0.011028576063405867\n",
      "threshold: 0.5 precision: 0.005529607567410775 recall: 0.37613770844540034 f1: 0.010898988892925896\n"
     ]
    }
   ],
   "source": [
    "thresh_ls = [0.005, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "for i in thresh_ls:\n",
    "  print('threshold:', i,\n",
    "        *[\"{}: {}\".format(name, num) for name, num in zip(\n",
    "          [\"precision\", \"recall\",\"f1\"],\n",
    "          score_model(all_true_labels, all_outputs, thresh=i))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
